Search.setIndex({"docnames": ["about/authors", "about/changelog", "about/index", "api/_autosummary/lmflow.args", "autoapi/index", "autoapi/lmflow/args/index", "autoapi/lmflow/datasets/dataset/index", "autoapi/lmflow/datasets/index", "autoapi/lmflow/index", "autoapi/lmflow/models/auto_model/index", "autoapi/lmflow/models/base_model/index", "autoapi/lmflow/models/decoder_model/index", "autoapi/lmflow/models/encoder_decoder_model/index", "autoapi/lmflow/models/hf_decoder_model/index", "autoapi/lmflow/models/hf_encoder_decoder_model/index", "autoapi/lmflow/models/index", "autoapi/lmflow/models/interfaces/index", "autoapi/lmflow/models/interfaces/tunable/index", "autoapi/lmflow/models/regression_model/index", "autoapi/lmflow/models/text_regression_model/index", "autoapi/lmflow/pipeline/auto_pipeline/index", "autoapi/lmflow/pipeline/base_aligner/index", "autoapi/lmflow/pipeline/base_pipeline/index", "autoapi/lmflow/pipeline/base_tuner/index", "autoapi/lmflow/pipeline/evaluator/index", "autoapi/lmflow/pipeline/finetuner/index", "autoapi/lmflow/pipeline/index", "autoapi/lmflow/pipeline/inferencer/index", "autoapi/lmflow/pipeline/raft_aligner/index", "autoapi/lmflow/pipeline/utils/index", "autoapi/lmflow/pipeline/utils/raft_trainer/index", "autoapi/lmflow/utils/constants/index", "autoapi/lmflow/utils/data_utils/index", "autoapi/lmflow/utils/index", "autoapi/lmflow/version/index", "documentation/data", "documentation/index", "documentation/infer", "documentation/model", "documentation/tuning", "examples/DATASETS", "examples/checkpoints", "examples/index", "examples/medical_finetune", "examples/raft", "examples/reward_modeling", "index"], "filenames": ["about/authors.md", "about/changelog.md", "about/index.md", "api/_autosummary/lmflow.args.rst", "autoapi/index.rst", "autoapi/lmflow/args/index.rst", "autoapi/lmflow/datasets/dataset/index.rst", "autoapi/lmflow/datasets/index.rst", "autoapi/lmflow/index.rst", "autoapi/lmflow/models/auto_model/index.rst", "autoapi/lmflow/models/base_model/index.rst", "autoapi/lmflow/models/decoder_model/index.rst", "autoapi/lmflow/models/encoder_decoder_model/index.rst", "autoapi/lmflow/models/hf_decoder_model/index.rst", "autoapi/lmflow/models/hf_encoder_decoder_model/index.rst", "autoapi/lmflow/models/index.rst", "autoapi/lmflow/models/interfaces/index.rst", "autoapi/lmflow/models/interfaces/tunable/index.rst", "autoapi/lmflow/models/regression_model/index.rst", "autoapi/lmflow/models/text_regression_model/index.rst", "autoapi/lmflow/pipeline/auto_pipeline/index.rst", "autoapi/lmflow/pipeline/base_aligner/index.rst", "autoapi/lmflow/pipeline/base_pipeline/index.rst", "autoapi/lmflow/pipeline/base_tuner/index.rst", "autoapi/lmflow/pipeline/evaluator/index.rst", "autoapi/lmflow/pipeline/finetuner/index.rst", "autoapi/lmflow/pipeline/index.rst", "autoapi/lmflow/pipeline/inferencer/index.rst", "autoapi/lmflow/pipeline/raft_aligner/index.rst", "autoapi/lmflow/pipeline/utils/index.rst", "autoapi/lmflow/pipeline/utils/raft_trainer/index.rst", "autoapi/lmflow/utils/constants/index.rst", "autoapi/lmflow/utils/data_utils/index.rst", "autoapi/lmflow/utils/index.rst", "autoapi/lmflow/version/index.rst", "documentation/data.md", "documentation/index.md", "documentation/infer.md", "documentation/model.md", "documentation/tuning.md", "examples/DATASETS.md", "examples/checkpoints.md", "examples/index.md", "examples/medical_finetune.md", "examples/raft.md", "examples/reward_modeling.md", "index.md"], "titles": ["Contributors", "Changelog", "About", "lmflow.args", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.args</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets.dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.auto_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.base_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.encoder_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_encoder_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces.tunable</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.text_regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.auto_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_tuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.evaluator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.finetuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.inferencer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.raft_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils.raft_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.data_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.version</span></code>", "Data", "Documentation", "Inference", "Model", "Fine-tuning", "Dataset", "Checkpoints", "Examples", "Finetune", "Reward rAnked FineTuning (RAFT)", "Reward Modeling", "LMFlow"], "terms": {"shizh": [0, 46], "diao": [0, 46], "rui": [0, 46], "pan": [0, 46], "hanz": [0, 46], "dong": [0, 46], "ka": 0, "shun": 0, "shum": [0, 46], "jipeng": [0, 46], "zhang": [0, 46], "wei": [0, 46], "xiong": [0, 46], "tong": [0, 46], "The": [1, 5, 6, 7, 11, 12, 13, 14, 20, 24, 25, 27, 28, 30, 32, 40, 44, 45, 46], "first": [1, 30, 41, 45], "public": 1, "task": [1, 13, 14, 30], "tune": [1, 13, 14, 23, 25, 30, 43, 44, 45], "instruct": [1, 45], "user": [1, 40, 44, 46], "defin": [1, 3, 5, 6, 7, 30, 40, 44], "dataset": [1, 3, 4, 5, 8, 13, 14, 19, 21, 23, 24, 25, 27, 28, 30, 32, 42, 43, 44, 45, 46], "A": [1, 6, 7, 11, 12, 13, 14, 19, 21, 23, 24, 28, 30, 32, 45], "simpl": [1, 30, 45], "extens": [1, 44, 46], "api": [1, 46], "develop": 1, "effici": [1, 46], "finetun": [1, 4, 8, 26, 40, 41, 46], "lora": [1, 13, 14, 44, 45, 46], "simplifi": [1, 24, 25, 27, 28, 45, 46], "model": [1, 3, 4, 5, 8, 21, 23, 24, 25, 27, 28, 30, 40, 41, 42, 43, 44, 46], "infer": [1, 13, 14, 19, 24, 27, 40, 46], "framework": [1, 44, 45], "changelog": [2, 46], "version": [2, 3, 4, 5, 8], "0": [2, 8, 13, 24, 27, 28, 30, 34, 41, 45, 46], "1": [2, 4, 5, 6, 7, 8, 13, 24, 30, 34, 40, 42, 43, 46], "mar": 2, "28": [2, 46], "2023": [2, 46], "contributor": [2, 46], "thi": [3, 4, 5, 6, 7, 11, 12, 13, 14, 28, 30, 32, 40, 44, 45, 46], "script": [3, 5, 30, 41, 43, 44, 45], "dataclass": [3, 5], "modelargu": [3, 5, 24, 25, 27, 28, 43], "datasetargu": [3, 5, 6, 7, 24, 25, 27, 28, 43], "contain": [3, 4, 5, 6, 7, 11, 12, 24, 25, 27, 28, 30, 40], "argument": [3, 5, 6, 7, 13, 14, 19, 24, 25, 27, 28, 30, 32, 43], "us": [3, 5, 10, 11, 12, 13, 14, 17, 18, 22, 24, 30, 31, 32, 40, 41, 42, 44, 45, 46], "train": [3, 5, 13, 14, 25, 28, 30, 32, 40, 44, 45, 46], "It": [3, 5, 13, 14, 24, 30, 45, 46], "import": [3, 5, 24, 30, 43, 44, 46], "sever": [3, 5, 13, 14, 30, 32, 40, 42], "modul": 3, "includ": [3, 5, 6, 7, 30, 32, 45, 46], "field": [3, 5, 45, 46], "from": [3, 5, 6, 7, 13, 14, 24, 30, 32, 41, 43, 44, 45, 46], "type": [3, 5, 6, 7, 9, 19, 30, 40, 44, 45], "option": [3, 5, 6, 7, 11, 12, 13, 14, 19, 25, 28, 30, 41], "require_vers": [3, 5], "transform": [3, 5, 13, 14, 30, 43], "util": [3, 4, 5, 8, 26, 28, 46], "model_for_causal_lm_map": [3, 5], "trainingargu": [3, 5, 30], "model_config_class": [3, 5], "i": [3, 5, 13, 14, 21, 23, 24, 28, 30, 40, 41, 44, 45, 46], "assign": [3, 5], "list": [3, 5, 13, 14, 30, 32, 40, 46], "config": [3, 5, 43, 45], "class": 3, "model_typ": [3, 5], "tupl": [3, 5, 30], "extract": [3, 5, 32], "page": [4, 46], "auto": [4, 5], "gener": [4, 5, 13, 14, 18, 24, 28, 30, 32, 41, 42, 44, 45, 46], "document": [4, 30], "lmflow": [4, 43, 44, 45], "interfac": [4, 8, 13, 14, 15], "tunabl": [4, 8, 13, 14, 15, 16, 23], "auto_model": [4, 8, 15], "base_model": [4, 8, 11, 12, 15, 18], "decoder_model": [4, 8, 13, 15], "encoder_decoder_model": [4, 8, 14, 15], "hf_decoder_model": [4, 8, 15], "hf_encoder_decoder_model": [4, 8, 15], "regression_model": [4, 8, 15, 19], "text_regression_model": [4, 8, 15], "pipelin": [4, 8, 40, 43, 44, 46], "raft_train": [4, 8, 26, 29], "auto_pipelin": [4, 8, 26, 43], "base_align": [4, 8, 26, 28], "base_pipelin": [4, 8, 21, 23, 24, 26, 27], "base_tun": [4, 8, 25, 26], "evalu": [4, 5, 8, 26, 30, 40, 41, 45, 46], "inferenc": [4, 5, 8, 26, 40], "raft_align": [4, 8, 26, 44], "constant": [4, 8, 33], "data_util": [4, 8, 33], "arg": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23, 25, 28, 30, 32, 43], "creat": [4, 6, 7, 10, 11, 12, 17, 18, 22, 24, 30, 45, 46], "sphinx": 4, "autoapi": 4, "sourc": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 40, 46], "decor": 5, "paramet": [5, 6, 7, 13, 14, 19, 24, 25, 27, 28, 30, 32, 45, 46], "can": [5, 13, 14, 30, 40, 41, 44, 45, 46], "configur": 5, "model_name_or_path": [5, 41, 45], "str": [5, 6, 7, 13, 14, 27, 30, 32, 44], "string": [5, 6, 7, 13, 14, 27, 30, 32], "repres": [5, 6, 7, 13, 14, 24], "path": [5, 13, 14, 19, 30, 41, 43], "name": [5, 13, 14, 19, 20, 30, 32], "pretrain": [5, 13, 14, 30, 41, 46], "checkpoint": [5, 30, 42, 44], "weight": [5, 24, 46], "initi": [5, 6, 7, 13, 14, 19, 24, 25, 27, 28, 30, 43], "If": [5, 30, 32, 43, 45, 46], "none": [5, 6, 7, 13, 14, 24, 28, 30, 32, 45], "scratch": 5, "provid": [5, 10, 11, 12, 13, 14, 17, 18, 22, 24, 30, 40, 42, 44, 45, 46], "config_overrid": 5, "default": [5, 6, 7, 13, 14, 30, 32], "set": [5, 13, 14, 30, 32, 40, 41, 44, 45], "overrid": [5, 30], "when": [5, 30, 45], "config_nam": 5, "differ": [5, 6, 7, 13, 14, 30, 41], "tokenizer_nam": 5, "token": [5, 13, 14, 24, 28, 30, 43, 45], "cache_dir": 5, "directori": [5, 13, 14, 24, 30, 40], "where": [5, 24, 40, 44, 45], "download": [5, 40, 41, 44], "huggingfac": [5, 6, 7, 13, 14, 41, 45], "co": 5, "store": 5, "use_fast_token": 5, "bool": [5, 30, 32], "boolean": 5, "indic": [5, 40], "whether": [5, 13, 14, 30], "fast": 5, "back": [5, 45], "librari": [5, 30], "model_revis": 5, "specif": [5, 45, 46], "branch": 5, "tag": [5, 30], "commit": [5, 30], "id": [5, 13, 14], "use_auth_token": 5, "run": [5, 24, 25, 28, 30, 40, 41, 45], "cli": 5, "login": 5, "necessari": [5, 30], "privat": 5, "torch_dtyp": 5, "dtype": [5, 30], "load": [5, 6, 7, 13, 14, 24, 25, 27, 28, 30, 32, 41], "under": [5, 30, 40, 44, 46], "pass": [5, 30, 43, 46], "automat": [5, 9, 20, 30], "deriv": 5, "": [5, 30, 43, 44, 45, 46], "use_ram_optimized_load": 5, "disk": 5, "map": [5, 6, 7, 19, 43, 45], "memori": 5, "enough": 5, "lora_model_path": [5, 41], "arch_typ": 5, "use_lora": 5, "lora_r": 5, "int": [5, 13, 14, 27, 30, 32, 45], "lora_alpha": 5, "lora_target_modul": 5, "lora_dropout": 5, "float": [5, 19, 24, 27, 30, 44], "save_aggregated_lora": 5, "__post_init__": 5, "languag": [5, 13, 14, 24, 25, 30, 44, 46], "dataset_path": [5, 41, 45], "dataset_nam": 5, "valu": [5, 30, 44], "custom": [5, 30, 40, 42, 45], "is_custom_dataset": 5, "data": [5, 6, 7, 19, 24, 25, 28, 30, 32, 40, 41, 44, 45, 46], "fals": [5, 13, 14, 30, 45], "customized_cache_dir": 5, "cach": [5, 30], "dataset_config_nam": 5, "via": [5, 44], "train_fil": 5, "input": [5, 13, 14, 19, 24, 27, 28, 30, 32, 40, 41, 45], "file": [5, 24, 30, 32, 40, 43, 46], "text": [5, 13, 14, 24, 25, 32, 40, 41, 43, 44, 45], "validation_fil": 5, "perplex": 5, "max_train_sampl": 5, "an": [5, 10, 11, 12, 17, 18, 22, 30, 44, 45, 46], "integ": 5, "maximum": [5, 24, 25, 30], "number": [5, 24, 30, 44], "exampl": [5, 11, 12, 30, 32, 40, 41, 44, 46], "debug": 5, "quicker": 5, "truncat": [5, 45], "max_eval_sampl": 5, "stream": [5, 44], "enabl": 5, "mode": [5, 30], "block_siz": 5, "sequenc": [5, 13, 14, 30], "length": [5, 13, 14, 24, 25, 30, 32], "after": [5, 40], "block": [5, 25, 30], "size": [5, 24, 30], "also": [5, 11, 12, 24, 30, 45, 46], "some": [5, 24, 30, 45, 46], "addit": [5, 30], "further": [5, 46], "overwrite_cach": 5, "validation_split_percentag": [5, 45], "preprocessing_num_work": 5, "disable_group_text": 5, "demo_example_in_prompt": 5, "explanation_in_prompt": 5, "keep_linebreak": 5, "prompt_structur": [5, 27, 41], "function": [5, 11, 12, 19, 28, 30, 44, 45, 46], "help": [5, 45, 46], "messag": [5, 6, 7, 30], "each": [5, 30, 40, 45], "hint": [5, 6, 7], "metadata": [5, 30], "inform": [5, 6, 7, 24, 30, 45, 46], "about": [5, 30, 44, 45, 46], "eval_dataset_path": 5, "group_texts_batch_s": 5, "test_fil": 5, "finetunerargu": [5, 25], "base": [5, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 44, 45, 46], "adapt": [5, 13, 14, 30, 46], "evaluatorargu": [5, 24], "local_rank": [5, 28], "For": [5, 30, 40, 42, 45, 46], "distribut": [5, 30], "random_shuffl": [5, 32], "use_wandb": [5, 24], "random_se": 5, "output_dir": [5, 30, 41], "mixed_precis": 5, "choic": [5, 32], "bf16": 5, "fp16": 5, "mix": 5, "precis": 5, "deepspe": [5, 13, 14, 30, 41, 43], "json": [5, 6, 7, 30, 32, 40, 41, 43, 45], "e": [5, 28, 30, 32, 46], "g": [5, 30], "ds_config": [5, 13, 14, 41], "alreadi": [5, 30, 45], "dict": [5, 6, 7, 30], "answer_typ": [5, 24, 32, 41], "evaluate_block_s": 5, "metric": [5, 24, 30], "inference_batch_size_per_devic": 5, "use_accelerator_for_evalu": 5, "inferencerargu": [5, 27], "devic": [5, 13, 14, 30], "do_sampl": 5, "raftalignerargu": [5, 28], "raft": [5, 42], "align": [5, 21, 28, 42], "output_reward_path": [5, 28], "output_min_length": [5, 28], "output_max_length": [5, 28], "num_raft_iter": 5, "raft_batch_s": 5, "top_reward_percentag": 5, "benchmarkingargu": 5, "lm_evaluation_metr": 5, "pipeline_argument_map": 5, "autoargu": [5, 43], "choos": [5, 30, 45], "get_pipeline_args_class": [5, 43], "python": [6, 7, 41, 46], "code": [6, 7, 30], "method": [6, 7, 13, 14, 24, 30, 46], "manipul": [6, 7], "backend": [6, 7, 13, 14, 30], "hug": [6, 7, 40], "face": [6, 7], "dictionari": [6, 7, 24, 25, 30], "retriev": [6, 7], "dataset_typ": 6, "text_onli": [6, 19, 40, 44, 45], "text2text": [6, 42], "float_onli": [6, 44], "key_typ": 6, "key_inst": 6, "instanc": [6, 7, 13, 14, 19, 24, 25, 30, 40, 44, 45, 46], "data_arg": [6, 7, 20, 24, 25, 27, 28, 43], "kwarg": [6, 7, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23, 25, 28, 30], "object": [6, 7, 19, 24, 25, 27, 28, 30], "given": [6, 7, 19, 24, 25, 27, 28, 30, 44, 45], "requir": [6, 7, 24, 25, 27, 28, 45, 46], "posit": [6, 7, 13, 14, 19, 25, 28, 44, 45, 46], "keyword": [6, 7, 13, 14, 19, 25, 28, 30], "_check_data_format": [6, 7], "check": [6, 7, 30], "structur": [6, 7, 45], "match": [6, 7], "rais": [6, 7, 30], "from_dict": [6, 7], "dict_obj": [6, 7], "return": [6, 7, 13, 14, 20, 24, 25, 27, 28, 30, 32, 44, 45], "format": [6, 7, 42], "key_1": [6, 7, 40], "value_1": [6, 7, 40], "key_2": [6, 7, 40], "2": [6, 7, 28, 40, 42, 43, 46], "value_2": [6, 7, 40], "self": [6, 7, 30], "classmethod": [6, 7, 9, 20], "create_from_dict": [6, 7, 44], "to_dict": [6, 7, 44], "get_backend": [6, 7], "get_backend_dataset": [6, 7], "backend_dataset": [6, 7], "get_data_arg": [6, 7], "get_typ": [6, 7], "internal_vers": 8, "__version__": [8, 34], "get": [9, 19, 28, 30, 41, 43, 45], "correct": 9, "automodel": 9, "get_model": 9, "model_arg": [9, 13, 14, 19, 20, 24, 25, 27, 28, 43], "basemodel": [10, 11, 12, 18, 28], "abc": [10, 11, 12, 17, 18, 22], "helper": [10, 11, 12, 17, 18, 22, 30], "standard": [10, 11, 12, 17, 18, 22], "wai": [10, 11, 12, 17, 18, 22, 30, 40, 41, 45], "inherit": [10, 11, 12, 17, 18, 22, 30], "one": [11, 12, 30, 43, 44, 45], "line": [11, 12], "summari": [11, 12, 30], "program": [11, 12, 32], "termin": [11, 12], "period": [11, 12], "leav": [11, 12], "blank": [11, 12], "rest": [11, 12], "docstr": [11, 12], "should": [11, 12, 30, 45], "overal": [11, 12, 13, 14, 46], "descript": [11, 12, 30], "mai": [11, 12, 30, 45], "brief": [11, 12], "export": [11, 12], "usag": [11, 12], "typic": [11, 12, 45], "foo": [11, 12], "classfoo": [11, 12], "bar": [11, 12], "functionbar": [11, 12], "decodermodel": [11, 13], "encoderdecodermodel": [12, 14], "call": [13, 14, 30], "hfdecodermodel": [13, 14, 24], "which": [13, 14, 21, 23, 24, 30, 40, 44, 45, 46], "wrapper": [13, 14, 30], "around": [13, 14], "ha": [13, 14, 24, 30, 40, 44], "__init__": [13, 14], "ar": [13, 14, 30, 40, 41, 45, 46], "fine": [13, 14, 30, 36, 45, 46], "take": [13, 14, 24, 28, 30], "tune_strategi": [13, 14], "attent": [13, 14], "mask": [13, 14], "fed": [13, 14, 30], "support": [13, 14, 41, 42, 44], "normal": [13, 14, 24], "allow": [13, 14, 30, 46], "howev": [13, 14, 41, 46], "strategi": [13, 14], "yet": [13, 14], "implement": [13, 14, 30], "conveni": [13, 14, 46], "variou": [13, 14, 30, 40, 46], "nlp": [13, 14], "classif": [13, 14, 30], "question": [13, 14, 28, 40], "answer": [13, 14, 32, 40, 45], "logger": [13, 14, 25, 28, 30], "gpu": [13, 14, 30], "use_acceler": [13, 14], "revis": [13, 14, 19], "etc": [13, 14, 19, 30, 46], "configu": [13, 14], "add_special_token": 13, "true": [13, 24, 25, 30, 32, 45], "full": [13, 14, 45, 46], "tokenized_dataset": [13, 14, 25, 43], "without": [13, 30, 45], "ani": [13, 30, 45, 46], "lead": [13, 44], "trail": 13, "special": [13, 46], "thei": [13, 30, 40, 45], "begin": 13, "Of": 13, "sentenc": 13, "end": [13, 30, 44], "encod": [13, 14, 24, 40], "union": [13, 14, 30], "perform": [13, 14, 24, 25, 27, 28, 30, 44, 45, 46], "process": [13, 14, 24, 25, 27, 28, 30, 42, 43, 44, 45, 46], "output": [13, 14, 24, 28, 30, 32, 40], "hello": 13, "world": [13, 44], "101": 13, "7592": 13, "1010": 13, "2088": 13, "102": 13, "batch": [13, 24, 30, 32, 45], "input_id": [13, 45], "attention_mask": [13, 45], "token_type_id": 13, "tensor": [13, 30], "decod": [13, 14, 24, 32, 40], "singl": [13, 30, 40, 45], "prompt": [13, 14, 28, 40, 45, 46], "merge_lora_weight": [13, 14], "save": [13, 14, 30, 41, 46], "dir": [13, 14], "save_full_model": [13, 14], "get_max_length": [13, 14, 43], "max": [13, 14, 24], "accept": [13, 14, 19, 24, 30, 40], "term": [13, 14], "get_token": [13, 14], "get_backend_model": [13, 14], "hfencoderdecodermodel": 14, "abstract": [14, 21, 23], "regress": [18, 19], "regressionmodel": [18, 19, 28], "textregressionmodel": 19, "register_inference_funct": [19, 44], "inference_func": 19, "regist": [19, 44], "result": [19, 44, 46], "onli": [19, 30, 40, 43, 45, 46], "its": [20, 30, 46], "pipeline_map": 20, "autopipelin": [20, 43], "design": [20, 46], "get_pipelin": [20, 43], "pipeline_nam": [20, 43], "pipeline_arg": [20, 43], "basetun": [21, 23, 25], "subclass": [21, 23, 30], "basepipelin": [21, 22, 23, 24, 27], "basealign": [21, 28], "_check_if_align": 21, "reward_model": [21, 28, 44], "_check_if_tun": 23, "packag": [24, 42, 46], "constructor": 24, "three": [24, 40, 45], "relat": [24, 45, 46], "evaluator_arg": 24, "other": [24, 30, 45, 46], "two": [24, 30, 45], "create_dataload": [24, 27], "test": [24, 30, 40, 41, 45, 46], "loader": 24, "iter": [24, 28, 30], "over": [24, 40, 45], "mini": 24, "Then": [24, 41, 45], "write": 24, "log": [24, 30], "consol": 24, "bias": [24, 44], "_match": 24, "predicted_answ": 24, "groundtruth": 24, "accuraci": [24, 45, 46], "verbos": 24, "tunablemodel": [24, 25, 27, 43], "_evaluate_acc": 24, "_evaluate_ppl": 24, "_evaluate_nl": 24, "neg": [24, 45, 46], "likelihood": 24, "nll": 24, "n": [24, 46], "sum_": 24, "j": [24, 45], "w_i": 24, "ln": 24, "p": 24, "w_": 24, "context_window": 24, "sampl": [24, 30, 40, 44, 45], "th": 24, "here": [24, 30, 45], "start": [24, 30, 45], "p_": 24, "window_length": 24, "finetuner_arg": 25, "group_text": [25, 43], "model_max_length": [25, 43], "group": [25, 30, 43], "togeth": [25, 30], "form": [25, 30], "transform_dataset_in_plac": 25, "rstrip_partial_utf8": 27, "inferencer_arg": 27, "max_new_token": 27, "100": [27, 30, 45], "temperatur": 27, "output_dataset": 27, "stream_infer": 27, "context": [27, 30], "token_per_step": 27, "end_str": 27, "input_dataset": 27, "raftalign": 28, "aligner_arg": 28, "raft_aligner_arg": 28, "_initialize_train": 28, "training_arg": [28, 30], "trainer": [28, 30], "_load_dataset": 28, "selected_dataset": 28, "prepar": [28, 30, 45, 46], "everi": [28, 30], "_load_input_dataset": 28, "dataload": [28, 30, 32], "torch": [28, 30, 32], "_get_batch_dataset_top": 28, "batch_input": 28, "alpha": 28, "iter_id": 28, "16": 28, "48": 28, "infer_batch_s": 28, "8": [28, 46], "generation_kwarg": 28, "feed": [28, 30], "reward": [28, 42], "_is_native_cpu_amp_avail": 30, "default_callback": 30, "default_progress_callback": 30, "is_sagemaker_mp_post_1_10": 30, "skip_first_batch": 30, "training_args_nam": 30, "bin": 30, "trainer_state_nam": 30, "trainer_st": 30, "optimizer_nam": 30, "optim": 30, "pt": 30, "scheduler_nam": 30, "schedul": 30, "scaler_nam": 30, "scaler": 30, "rafttrain": 30, "modeling_util": 30, "pretrainedmodel": 30, "nn": [30, 45], "data_col": 30, "datacol": 30, "train_dataset": [30, 45], "eval_dataset": [30, 45], "tokenization_utils_bas": 30, "pretrainedtokenizerbas": 30, "model_init": 30, "callabl": 30, "compute_metr": 30, "trainer_util": 30, "evalpredict": 30, "callback": 30, "trainer_callback": 30, "trainercallback": 30, "lr_schedul": 30, "lambdalr": 30, "preprocess_logits_for_metr": 30, "featur": 30, "complet": [30, 46], "eval": [30, 45], "loop": 30, "pytorch": 30, "predict": 30, "must": [30, 43, 46], "tip": 30, "work": [30, 44, 45], "you": [30, 41, 45, 46], "still": [30, 45, 46], "your": [30, 42, 44, 45], "own": [30, 40, 44, 45], "long": [30, 40], "same": [30, 45], "tweak": 30, "Will": 30, "basic": 30, "tmp_trainer": 30, "current": [30, 40], "element": [30, 46], "default_data_col": 30, "datacollatorwithpad": 30, "otherwis": 30, "iterabledataset": 30, "column": 30, "forward": 30, "remov": 30, "note": [30, 46], "random": [30, 32], "fashion": 30, "either": 30, "intern": 30, "ident": 30, "all": [30, 41, 45, 46], "manual": 30, "seed": [30, 32], "epoch": 30, "have": [30, 40, 41, 44, 45, 46], "set_epoch": 30, "rng": 30, "prepend": 30, "kei": [30, 40, 45], "preprocess": [30, 45], "pad": 30, "along": 30, "make": [30, 45, 46], "easier": 30, "rerun": 30, "interrupt": 30, "reus": 30, "instanti": 30, "new": [30, 45, 46], "zero": 30, "optuna": 30, "rai": 30, "sigopt": 30, "trial": [30, 45], "abl": [30, 45], "architectur": 30, "accord": 30, "hyper": 30, "layer": 30, "count": 30, "inner": 30, "dropout": 30, "probabl": [30, 45], "comput": 30, "add": 30, "those": 30, "detail": [30, 42, 45], "want": [30, 45], "remove_callback": 30, "adamw": 30, "get_linear_schedule_with_warmup": 30, "control": 30, "logit": 30, "right": 30, "befor": [30, 46], "them": [30, 41, 45, 46], "step": [30, 42], "label": [30, 45], "onc": 30, "desir": [30, 45], "modif": 30, "made": [30, 45], "reflect": 30, "receiv": 30, "second": [30, 41], "doe": [30, 46], "alwai": [30, 45], "point": 30, "core": 30, "model_wrap": 30, "most": [30, 40, 45], "extern": 30, "case": [30, 41, 45], "more": [30, 44, 45, 46], "wrap": 30, "origin": [30, 41, 45], "again": 30, "distributeddataparallel": 30, "hasn": 30, "t": [30, 45], "been": 30, "is_model_parallel": 30, "switch": [30, 45], "parallel": 30, "mean": [30, 45], "split": [30, 45], "place_model_on_devic": 30, "place": [30, 45], "overridden": 30, "is_in_train": 30, "while": [30, 46], "add_callback": 30, "In": [30, 41, 44, 45], "member": 30, "pop_callback": 30, "found": [30, 46], "error": 30, "pop": 30, "_move_model_to_devic": 30, "_set_signature_columns_if_need": 30, "_remove_unused_column": 30, "_get_collator_with_removed_column": 30, "collat": 30, "unus": 30, "_get_train_sampl": 30, "sampler": 30, "get_train_dataload": 30, "__len__": 30, "inject": 30, "behavior": 30, "_get_eval_sampl": 30, "get_eval_dataload": 30, "get_test_dataload": 30, "test_dataset": 30, "create_optimizer_and_schedul": 30, "num_training_step": 30, "setup": 30, "learn": [30, 44, 45, 46], "rate": 30, "we": [30, 40, 42, 43, 44, 45, 46], "reason": [30, 45], "well": [30, 44, 46], "someth": [30, 45], "els": [30, 43, 45], "init": 30, "through": 30, "create_optim": 30, "create_schedul": 30, "static": 30, "get_optimizer_cls_and_kwarg": 30, "session": 30, "up": [30, 45], "do": [30, 45, 46], "num_exampl": 30, "access": [30, 41, 46], "exist": 30, "estim": 30, "best": [30, 44, 45], "_hp_search_setup": 30, "hp": 30, "search": [30, 46], "_report_to_hp_search": 30, "_tune_save_checkpoint": 30, "call_model_init": 30, "torch_jit_model_ev": 30, "ipex_optimize_model": 30, "float32": 30, "_wrap_model": 30, "resume_from_checkpoint": 30, "ignore_keys_for_ev": 30, "is_first_tim": 30, "main": [30, 43, 46], "entri": 30, "local": 30, "previou": [30, 44, 45], "equal": 30, "last": [30, 45], "present": 30, "resum": 30, "state": 30, "hyperparamet": 30, "ignor": 30, "gather": 30, "dure": 30, "hide": [30, 45], "deprec": 30, "_one_train": 30, "batch_siz": [30, 32], "_inner_training_loop": 30, "serv": [30, 46], "time": [30, 45], "updat": [30, 45], "_get_output_dir": 30, "_load_from_checkpoint": 30, "_load_best_model": 30, "_issue_warnings_after_load": 30, "load_result": 30, "_maybe_log_save_evalu": 30, "tr_loss": 30, "_load_rng_stat": 30, "_save_checkpoint": 30, "_load_optimizer_and_schedul": 30, "hyperparameter_search": 30, "hp_space": 30, "compute_object": 30, "n_trial": 30, "20": 30, "direct": [30, 46], "minim": 30, "hpsearchbackend": 30, "hp_name": 30, "bestrun": 30, "launch": 30, "quantiti": 30, "determin": 30, "loss": [30, 45], "sum": 30, "warn": 30, "To": [30, 40, 44, 45, 46], "need": [30, 41, 44, 45, 46], "reiniti": 30, "incompat": 30, "so": [30, 44, 45, 46], "space": [30, 45], "default_hp_space_optuna": 30, "default_hp_space_rai": 30, "default_hp_space_sigopt": 30, "depend": [30, 45], "maxim": [30, 46], "default_compute_object": 30, "greater": 30, "lower": 30, "pick": 30, "valid": 30, "training_util": 30, "instal": 30, "create_studi": 30, "see": [30, 45], "http": [30, 45, 46], "readthedoc": 30, "io": [30, 46], "en": 30, "stabl": 30, "refer": [30, 42, 46], "studi": [30, 45], "html": 30, "doc": 30, "latest": 30, "api_doc": 30, "execut": 30, "app": 30, "com": [30, 46], "endpoint": 30, "experi": [30, 44], "run_summari": 30, "watch": 30, "_prepare_input": 30, "nest": 30, "convert": [30, 32, 41], "handl": 30, "potenti": 30, "compute_loss_context_manag": 30, "manag": 30, "autocast_smart_context_manag": 30, "cache_en": 30, "appropri": [30, 45], "autocast": 30, "situat": [30, 45], "training_step": 30, "target": [30, 46], "unpack": 30, "being": [30, 45], "expect": 30, "compute_loss": 30, "return_output": 30, "how": [30, 42, 45], "By": [30, 41, 46], "is_local_process_zero": 30, "machin": [30, 46], "is_world_process_zero": 30, "global": 30, "go": [30, 41], "save_model": 30, "_internal_cal": 30, "reload": 30, "from_pretrain": 30, "_save_tpu": 30, "_save": 30, "state_dict": 30, "store_flo": 30, "_sorted_checkpoint": 30, "checkpoint_prefix": 30, "prefix_checkpoint_dir": 30, "use_mtim": 30, "_rotate_checkpoint": 30, "ignore_kei": 30, "metric_key_prefix": 30, "respons": [30, 32, 44, 45, 46], "wish": 30, "lst": 30, "prefix": [30, 45], "bleu": 30, "eval_bleu": 30, "come": 30, "predictionoutput": 30, "like": [30, 45, 46], "test_bleu": 30, "becaus": 30, "re": [30, 45], "dynam": 30, "concaten": 30, "arrai": 30, "index": [30, 46], "namedtupl": 30, "follow": [30, 40, 45, 46], "np": 30, "ndarrai": 30, "label_id": 30, "evaluation_loop": 30, "prediction_loss_onli": 30, "evalloopoutput": 30, "share": [30, 44], "both": [30, 44, 46], "_nested_gath": 30, "numpi": [30, 32], "_pad_across_process": 30, "pad_index": 30, "recurs": 30, "safe": [30, 45], "prediction_step": 30, "floating_point_op": 30, "oper": 30, "backward": 30, "anoth": 30, "init_git_repo": 30, "at_init": 30, "git": [30, 46], "repo": 30, "hub_model_id": 30, "overwrite_output_dir": 30, "might": [30, 45], "wipe": 30, "out": [30, 45, 46], "create_model_card": 30, "licens": 30, "model_nam": 30, "finetuned_from": 30, "dataset_tag": 30, "dataset_arg": 30, "draft": 30, "card": 30, "avail": [30, 40, 46], "applic": [30, 46], "hub": 30, "One": 30, "identifi": 30, "_push_from_checkpoint": 30, "checkpoint_fold": 30, "push_to_hub": 30, "commit_messag": 30, "upload": 30, "push": 30, "finish": 30, "url": [30, 46], "repositori": [30, 46], "track": 30, "progress": 30, "prediction_loop": 30, "_gather_and_numpifi": 30, "_add_sm_patterns_to_gitignor": 30, "sagemak": 30, "pattern": 30, "gitignor": 30, "commonli": [31, 46], "text_only_dataset_descript": 31, "text_only_dataset_detail": 31, "text2text_dataset_descript": 31, "text2text_dataset_detail": 31, "float_only_dataset_descript": 31, "text_only_dataset_long_descrit": 31, "text2text_dataset_long_descrit": 31, "dataset_description_map": 31, "instance_fields_map": 31, "set_random_se": 32, "cuda": 32, "load_data": 32, "file_nam": 32, "len": [32, 43, 45], "batchliz": 32, "shuffl": 32, "answer_extract": 32, "funtion": 32, "plain": 32, "b": 32, "c": 32, "d": [32, 45], "mutipl": 32, "qa": 32, "cd": [40, 41, 44], "sh": [40, 41, 44, 45], "strongli": 40, "encourag": [40, 44], "sinc": 40, "appli": [40, 46], "engin": 40, "techniqu": [40, 46], "As": [40, 45], "below": [40, 46], "our": [40, 41, 42, 43, 44, 46], "specifi": 40, "path_to_dataset": 40, "data_1": 40, "data_2": 40, "another_data": 40, "shall": [40, 46], "four": 40, "key_3": 40, "3": [40, 46], "key_4": 40, "4": [40, 46], "value_3": 40, "correspond": 40, "interpret": 40, "common": [40, 46], "raw": 40, "Its": [40, 46], "sample_text_1": 40, "sample_text_2": 40, "sample_text_3": 40, "example_dataset": 40, "train_50": 40, "abov": [40, 45], "mostli": 40, "pair": 40, "sample_input_1": 40, "sample_output_1": 40, "sample_input_2": 40, "sample_output_2": 40, "sample_input_3": 40, "sample_output_3": 40, "test_13": 40, "directli": [41, 46], "slightli": 41, "due": 41, "copyright": 41, "issu": [41, 44, 46], "facebookresearch": 41, "offici": 41, "hf": 41, "convert_llama_weights_to_hf": 41, "py": [41, 44, 45], "input_dir": 41, "model_s": 41, "7b": [41, 44, 45, 46], "good": [41, 45], "enjoi": [41, 45], "now": 41, "With": 41, "output_model": [41, 44], "obtain": [41, 44, 46], "similar": 41, "run_evaluation_with_lora": 41, "cuda_visible_devic": 41, "diff": 41, "alpaca": 41, "show": [42, 45], "problem": [42, 45], "textonli": 42, "llama": [42, 44, 45, 46], "sft": 42, "introduct": 42, "supervis": [42, 44], "rank": [42, 45], "algorithm": 42, "demo": 42, "sy": 43, "hfargumentpars": 43, "tunable_model": 43, "def": [43, 44, 45], "pars": 43, "pipelineargu": 43, "parser": 43, "argv": 43, "endswith": 43, "let": [43, 45], "parse_json_fil": 43, "json_fil": 43, "o": 43, "abspath": 43, "parse_args_into_dataclass": 43, "todo": 43, "done": [43, 44], "main_process_first": 43, "desc": 43, "lm_dataset": 43, "tuned_model": 43, "unsupervis": 44, "foundat": [44, 46], "implicit": 44, "Such": 44, "low": 44, "qualiti": 44, "unfair": 44, "substanti": 44, "consequ": 44, "therefor": [44, 46], "human": [44, 45, 46], "ethic": 44, "prefer": [44, 45], "becom": 44, "crucial": [44, 46], "procedur": [44, 45], "ensur": 44, "behav": 44, "real": 44, "scenario": 44, "primarili": 44, "reli": [44, 46], "reinforc": [44, 45], "feedback": [44, 45], "rlhf": [44, 45], "overcom": 44, "rl": 44, "despit": [44, 46], "feasibl": 44, "ineffici": 44, "instabl": 44, "often": 44, "pose": 44, "signific": [44, 46], "challeng": [44, 45], "urgent": 44, "streamlin": [44, 46], "enhanc": [44, 46], "propos": 44, "suffici": 44, "reject": [44, 45], "ill": 44, "ones": 44, "construct": 44, "offlin": 44, "onlin": 44, "furthermor": 44, "gradient": 44, "free": 44, "black": 44, "box": 44, "demonstr": [44, 46], "larg": [44, 46], "movi": 44, "review": 44, "chatbot": 44, "topic": 44, "interact": [44, 45], "bot": 44, "favorit": 44, "wa": 44, "run_raft_align": 44, "llama7b": 44, "reward_of": 44, "part": 44, "reward_funct": 44, "text_dataset": 44, "data_dict": 44, "assert": 44, "text_list": 44, "reward_list": 44, "guid": 45, "adjust": 45, "instructgpt": [45, 46], "paper": 45, "arxiv": 45, "org": 45, "ab": 45, "2203": 45, "02155": 45, "dahoa": 45, "hh": 45, "consist": 45, "assist": 45, "particular": [45, 46], "chosen": 45, "compar": [45, 46], "112k": 45, "12": 45, "5k": 45, "what": 45, "kind": 45, "nois": 45, "did": 45, "dinosaur": 45, "didn": 45, "live": 45, "realli": 45, "hard": 45, "sai": 45, "find": 45, "would": 45, "ye": 45, "guess": 45, "lot": 45, "read": 45, "certain": 45, "amount": 45, "imagin": 45, "cant": 45, "stuff": 45, "don": 45, "know": 45, "10k": 45, "12k": 45, "10": 45, "hh_rlhf": 45, "ad": 45, "post": 45, "illustr": 45, "bui": 45, "protect": 45, "cell": 45, "phone": 45, "circumst": 45, "carri": 45, "pocket": 45, "purs": 45, "But": 45, "quick": 45, "actual": 45, "caus": 45, "harm": 45, "than": 45, "parent": 45, "home": 45, "could": 45, "damag": [45, 46], "screen": 45, "thing": 45, "troubl": 45, "turn": 45, "off": 45, "won": 45, "anyth": 45, "afford": 45, "replac": 45, "peopl": 45, "aren": 45, "thank": 45, "me": 45, "welcom": 45, "m": 45, "try": 45, "salam": 45, "witch": 45, "look": 45, "book": 45, "witchcraft": 45, "recommend": 45, "histor": 45, "salem": 45, "1692": 45, "interest": 45, "histori": 45, "persecut": 45, "coloni": 45, "america": 45, "cultur": 45, "phenomenon": 45, "excel": 45, "religion": 45, "declin": 45, "magic": 45, "popular": 45, "belief": 45, "sixteenth": 45, "seventeenth": 45, "centuri": 45, "england": 45, "keith": 45, "thoma": 45, "otherworld": 45, "anthropologi": 45, "superstit": 45, "jack": 45, "goodi": 45, "popish": 45, "plot": 45, "prelat": 45, "k": 45, "everett": 45, "edit": 45, "run_finetun": 45, "modifi": 45, "eleutherai": 45, "gpt": [45, 46], "neo": 45, "3b": 45, "project_dir": 45, "command": [45, 46], "run_finetune_with_lora": 45, "involv": 45, "fortun": 45, "former": 45, "heater": 45, "give": 45, "fire": 45, "hazard": 45, "tell": 45, "fireplac": 45, "room": 45, "materi": 45, "feel": 45, "heat": 45, "touch": 45, "just": 45, "fuel": 45, "surround": 45, "sure": 45, "correctli": 45, "sort": 45, "That": 45, "glad": 45, "happi": 45, "teach": [45, 46], "my": 45, "kid": 45, "fort": 45, "build": 45, "Or": 45, "elabor": 45, "exactli": 45, "mayb": 45, "idea": 45, "There": 45, "mani": 45, "simplest": 45, "pile": 45, "furnitur": 45, "hous": 45, "although": 45, "bit": 45, "taller": 45, "sturdier": 45, "easi": 45, "fun": 45, "explor": 45, "improv": [45, 46], "run_reward_model": 45, "addition": 45, "select": 45, "percentag": 45, "load_dataset": 45, "build_dataset": 45, "assum": [45, 46], "organ": 45, "answer_posit": 45, "answer_neg": 45, "tokenized_po": 45, "tokenized_neg": 45, "chosen_input_id": 45, "chosen_attention_mask": 45, "rejected_input_id": 45, "rejected_attention_mask": 45, "data_fil": 45, "filter": 45, "lambda": 45, "x": 45, "512": 45, "idx_gap": 45, "rang": [45, 46], "logsigmoid": 45, "chosen_reward": 45, "rejected_reward": 45, "5": [45, 46], "record": 45, "remark": [45, 46], "79": 45, "52": 45, "wandb": 45, "ai": [45, 46], "weixiong5237": 45, "t3uwm8yp": 45, "71": 45, "64": [45, 46], "p2ju3r1a": 45, "rm": 45, "69": [45, 46], "24": [45, 46], "8fc1rcf8": 45, "65": [45, 46], "58": [45, 46], "7oemwynu": 45, "10000": 45, "toolbox": 46, "friendli": 46, "speedi": 46, "reliabl": 46, "entir": 46, "commun": 46, "backbon": 46, "galactica": 46, "light": 46, "extrem": 46, "few": 46, "33b": 46, "25mb": 46, "storag": 46, "orient": 46, "chatgpt": 46, "open": 46, "whole": 46, "achiev": 46, "expans": 46, "except": 46, "capac": 46, "attain": 46, "intellig": 46, "surpass": 46, "convent": 46, "grow": 46, "cater": 46, "maintain": 46, "compet": 46, "pleas": 46, "introduc": 46, "lightweight": 46, "toolkit": 46, "thoughtfulli": 46, "easili": 46, "scalabl": 46, "tool": 46, "publicli": 46, "effect": 46, "thoroughli": 46, "github": 46, "goal": 46, "profici": 46, "medicin": 46, "mathemat": 46, "acquir": 46, "domain": 46, "better": 46, "subject": 46, "matter": 46, "medic": 46, "gain": 46, "knowledg": 46, "emphas": 46, "pubmedqa": 46, "medmcqa": 46, "observ": 46, "medqa": 46, "usml": 46, "averag": 46, "60": 46, "50": 46, "expert": 46, "78": 46, "87": 46, "90": 46, "85": 46, "175b": 46, "73": 46, "46": 46, "44": 46, "54": 46, "63": 46, "9": 46, "57": 46, "7": 46, "55": 46, "27": 46, "18": 46, "43": 46, "30": 46, "25": 46, "75": 46, "49": 46, "56": 46, "74": 46, "51": 46, "moreov": 46, "mmlu": 46, "verifi": 46, "robust": 46, "anatomi": 46, "clinic": 46, "colleg": 46, "biologi": 46, "genet": 46, "profession": 46, "39": 46, "40": 46, "32": 46, "36": 46, "30b": 46, "26": 46, "23": 46, "120b": 46, "59": 46, "68": 46, "6": 46, "opt": 46, "21": 46, "35": 46, "bloom": 46, "176b": 46, "37": 46, "29": 46, "gopher": 46, "280b": 46, "67": 46, "70": 46, "gpt3": 46, "72": 46, "61": 46, "66": 46, "natur": 46, "constraint": 46, "abil": 46, "multipl": 46, "unseen": 46, "understand": 46, "incorpor": 46, "cue": 46, "relev": 46, "hand": 46, "power": 46, "wide": 46, "area": 46, "approach": 46, "unlock": 46, "level": 46, "product": 46, "jsonl": 46, "clone": 46, "optimalscal": 46, "conda": 46, "y": 46, "activ": 46, "mpi4pi": 46, "pip": 46, "readm": 46, "misc": 46, "author": 46, "kashun": 46, "titl": 46, "year": 46, "publish": 46, "journal": 46, "howpublish": 46, "aim": 46, "intend": 46, "li": 46, "sole": 46, "guarante": 46, "legal": 46, "compon": 46, "awar": 46, "risk": 46, "liabil": 46, "associ": 46, "commerci": 46, "technic": 46, "advic": 46, "held": 46, "indirect": 46, "incident": 46, "consequenti": 46, "improp": 46, "highlight": 46, "probabilist": 46, "seek": 46, "outcom": 46, "account": 46, "relianc": 46, "submit": 46}, "objects": {"": [[8, 0, 0, "-", "lmflow"]], "lmflow": [[8, 1, 1, "", "__version__"], [5, 0, 0, "-", "args"], [7, 0, 0, "-", "datasets"], [8, 1, 1, "", "internal_version"], [15, 0, 0, "-", "models"], [26, 0, 0, "-", "pipeline"], [33, 0, 0, "-", "utils"], [34, 0, 0, "-", "version"]], "lmflow.args": [[5, 2, 1, "", "AutoArguments"], [5, 2, 1, "", "BenchmarkingArguments"], [5, 2, 1, "", "DatasetArguments"], [5, 2, 1, "", "EvaluatorArguments"], [5, 2, 1, "", "FinetunerArguments"], [5, 2, 1, "", "InferencerArguments"], [5, 1, 1, "", "MODEL_CONFIG_CLASSES"], [5, 1, 1, "", "MODEL_TYPES"], [5, 2, 1, "", "ModelArguments"], [5, 1, 1, "", "PIPELINE_ARGUMENT_MAPPING"], [5, 2, 1, "", "RaftAlignerArguments"]], "lmflow.args.AutoArguments": [[5, 3, 1, "", "get_pipeline_args_class"]], "lmflow.args.BenchmarkingArguments": [[5, 4, 1, "", "dataset_name"], [5, 4, 1, "", "lm_evaluation_metric"]], "lmflow.args.DatasetArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "", "block_size"], [5, 4, 1, "", "customized_cache_dir"], [5, 4, 1, "", "dataset_config_name"], [5, 4, 1, "", "dataset_name"], [5, 4, 1, "", "dataset_path"], [5, 4, 1, "", "disable_group_texts"], [5, 4, 1, "", "eval_dataset_path"], [5, 4, 1, "", "group_texts_batch_size"], [5, 4, 1, "", "is_custom_dataset"], [5, 4, 1, "", "keep_linebreaks"], [5, 4, 1, "", "max_eval_samples"], [5, 4, 1, "", "max_train_samples"], [5, 4, 1, "", "overwrite_cache"], [5, 4, 1, "", "preprocessing_num_workers"], [5, 4, 1, "", "streaming"], [5, 4, 1, "", "test_file"], [5, 4, 1, "", "train_file"], [5, 4, 1, "", "validation_file"], [5, 4, 1, "", "validation_split_percentage"]], "lmflow.args.EvaluatorArguments": [[5, 4, 1, "", "answer_type"], [5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "evaluate_block_size"], [5, 4, 1, "", "inference_batch_size_per_device"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "metric"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "output_dir"], [5, 4, 1, "", "prompt_structure"], [5, 4, 1, "", "random_seed"], [5, 4, 1, "", "random_shuffle"], [5, 4, 1, "", "use_accelerator_for_evaluator"], [5, 4, 1, "", "use_wandb"]], "lmflow.args.InferencerArguments": [[5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "device"], [5, 4, 1, "", "do_sample"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "random_seed"]], "lmflow.args.ModelArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "id0", "arch_type"], [5, 4, 1, "", "cache_dir"], [5, 4, 1, "", "config_name"], [5, 4, 1, "", "config_overrides"], [5, 4, 1, "", "lora_alpha"], [5, 4, 1, "", "lora_dropout"], [5, 4, 1, "", "lora_model_path"], [5, 4, 1, "", "lora_r"], [5, 4, 1, "", "lora_target_modules"], [5, 4, 1, "", "model_name_or_path"], [5, 4, 1, "", "model_revision"], [5, 4, 1, "", "model_type"], [5, 4, 1, "", "save_aggregated_lora"], [5, 4, 1, "", "tokenizer_name"], [5, 4, 1, "", "torch_dtype"], [5, 4, 1, "", "use_auth_token"], [5, 4, 1, "", "use_fast_tokenizer"], [5, 4, 1, "", "use_lora"], [5, 4, 1, "", "use_ram_optimized_load"]], "lmflow.args.RaftAlignerArguments": [[5, 4, 1, "", "inference_batch_size_per_device"], [5, 4, 1, "", "num_raft_iteration"], [5, 4, 1, "", "output_max_length"], [5, 4, 1, "", "output_min_length"], [5, 4, 1, "", "output_reward_path"], [5, 4, 1, "", "raft_batch_size"], [5, 4, 1, "", "top_reward_percentage"]], "lmflow.datasets": [[7, 2, 1, "", "Dataset"], [6, 0, 0, "-", "dataset"]], "lmflow.datasets.Dataset": [[7, 3, 1, "", "_check_data_format"], [7, 3, 1, "", "create_from_dict"], [7, 3, 1, "", "from_dict"], [7, 3, 1, "", "get_backend"], [7, 3, 1, "", "get_backend_dataset"], [7, 3, 1, "", "get_data_args"], [7, 3, 1, "", "get_type"], [7, 3, 1, "", "map"], [7, 3, 1, "", "to_dict"]], "lmflow.datasets.dataset": [[6, 1, 1, "", "DATASET_TYPES"], [6, 2, 1, "", "Dataset"], [6, 1, 1, "", "KEY_INSTANCES"], [6, 1, 1, "", "KEY_TYPE"]], "lmflow.datasets.dataset.Dataset": [[6, 3, 1, "", "_check_data_format"], [6, 3, 1, "", "create_from_dict"], [6, 3, 1, "", "from_dict"], [6, 3, 1, "", "get_backend"], [6, 3, 1, "", "get_backend_dataset"], [6, 3, 1, "", "get_data_args"], [6, 3, 1, "", "get_type"], [6, 3, 1, "", "map"], [6, 3, 1, "", "to_dict"]], "lmflow.models": [[9, 0, 0, "-", "auto_model"], [10, 0, 0, "-", "base_model"], [11, 0, 0, "-", "decoder_model"], [12, 0, 0, "-", "encoder_decoder_model"], [13, 0, 0, "-", "hf_decoder_model"], [14, 0, 0, "-", "hf_encoder_decoder_model"], [16, 0, 0, "-", "interfaces"], [18, 0, 0, "-", "regression_model"], [19, 0, 0, "-", "text_regression_model"]], "lmflow.models.auto_model": [[9, 2, 1, "", "AutoModel"]], "lmflow.models.auto_model.AutoModel": [[9, 3, 1, "", "get_model"]], "lmflow.models.base_model": [[10, 2, 1, "", "BaseModel"]], "lmflow.models.decoder_model": [[11, 2, 1, "", "DecoderModel"]], "lmflow.models.encoder_decoder_model": [[12, 2, 1, "", "EncoderDecoderModel"]], "lmflow.models.hf_decoder_model": [[13, 2, 1, "", "HFDecoderModel"], [13, 1, 1, "", "logger"]], "lmflow.models.hf_decoder_model.HFDecoderModel": [[13, 3, 1, "", "decode"], [13, 3, 1, "", "encode"], [13, 3, 1, "", "get_backend_model"], [13, 3, 1, "", "get_max_length"], [13, 3, 1, "", "get_tokenizer"], [13, 3, 1, "", "inference"], [13, 3, 1, "", "merge_lora_weights"], [13, 3, 1, "", "save"], [13, 3, 1, "", "tokenize"]], "lmflow.models.hf_encoder_decoder_model": [[14, 2, 1, "", "HFEncoderDecoderModel"], [14, 1, 1, "", "logger"]], "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel": [[14, 3, 1, "", "decode"], [14, 3, 1, "", "encode"], [14, 3, 1, "", "get_backend_model"], [14, 3, 1, "", "get_max_length"], [14, 3, 1, "", "get_tokenizer"], [14, 3, 1, "", "inference"], [14, 3, 1, "", "merge_lora_weights"], [14, 3, 1, "", "save"], [14, 3, 1, "", "tokenize"]], "lmflow.models.interfaces": [[17, 0, 0, "-", "tunable"]], "lmflow.models.interfaces.tunable": [[17, 2, 1, "", "Tunable"]], "lmflow.models.regression_model": [[18, 2, 1, "", "RegressionModel"]], "lmflow.models.text_regression_model": [[19, 2, 1, "", "TextRegressionModel"]], "lmflow.models.text_regression_model.TextRegressionModel": [[19, 3, 1, "", "inference"], [19, 3, 1, "", "register_inference_function"]], "lmflow.pipeline": [[20, 0, 0, "-", "auto_pipeline"], [21, 0, 0, "-", "base_aligner"], [22, 0, 0, "-", "base_pipeline"], [23, 0, 0, "-", "base_tuner"], [24, 0, 0, "-", "evaluator"], [25, 0, 0, "-", "finetuner"], [27, 0, 0, "-", "inferencer"], [28, 0, 0, "-", "raft_aligner"], [29, 0, 0, "-", "utils"]], "lmflow.pipeline.auto_pipeline": [[20, 2, 1, "", "AutoPipeline"], [20, 1, 1, "", "PIPELINE_MAPPING"]], "lmflow.pipeline.auto_pipeline.AutoPipeline": [[20, 3, 1, "", "get_pipeline"]], "lmflow.pipeline.base_aligner": [[21, 2, 1, "", "BaseAligner"]], "lmflow.pipeline.base_aligner.BaseAligner": [[21, 3, 1, "", "_check_if_alignable"], [21, 3, 1, "", "align"]], "lmflow.pipeline.base_pipeline": [[22, 2, 1, "", "BasePipeline"]], "lmflow.pipeline.base_tuner": [[23, 2, 1, "", "BaseTuner"]], "lmflow.pipeline.base_tuner.BaseTuner": [[23, 3, 1, "", "_check_if_tunable"], [23, 3, 1, "", "tune"]], "lmflow.pipeline.evaluator": [[24, 2, 1, "", "Evaluator"]], "lmflow.pipeline.evaluator.Evaluator": [[24, 3, 1, "", "_evaluate_acc"], [24, 3, 1, "", "_evaluate_nll"], [24, 3, 1, "", "_evaluate_ppl"], [24, 3, 1, "", "_match"], [24, 3, 1, "", "create_dataloader"], [24, 3, 1, "", "evaluate"]], "lmflow.pipeline.finetuner": [[25, 2, 1, "", "Finetuner"], [25, 1, 1, "", "logger"]], "lmflow.pipeline.finetuner.Finetuner": [[25, 3, 1, "", "group_text"], [25, 3, 1, "", "tune"]], "lmflow.pipeline.inferencer": [[27, 2, 1, "", "Inferencer"], [27, 5, 1, "", "rstrip_partial_utf8"]], "lmflow.pipeline.inferencer.Inferencer": [[27, 3, 1, "", "create_dataloader"], [27, 3, 1, "", "inference"], [27, 3, 1, "", "stream_inference"]], "lmflow.pipeline.raft_aligner": [[28, 2, 1, "", "RaftAligner"], [28, 1, 1, "", "logger"]], "lmflow.pipeline.raft_aligner.RaftAligner": [[28, 3, 1, "", "_get_batch_dataset_top"], [28, 3, 1, "", "_initialize_trainer"], [28, 3, 1, "", "_load_dataset"], [28, 3, 1, "", "_load_input_dataset"], [28, 3, 1, "", "align"]], "lmflow.pipeline.utils": [[30, 0, 0, "-", "raft_trainer"]], "lmflow.pipeline.utils.raft_trainer": [[30, 1, 1, "", "DEFAULT_CALLBACKS"], [30, 1, 1, "id0", "DEFAULT_PROGRESS_CALLBACK"], [30, 1, 1, "", "IS_SAGEMAKER_MP_POST_1_10"], [30, 1, 1, "", "OPTIMIZER_NAME"], [30, 2, 1, "", "RaftTrainer"], [30, 1, 1, "", "SCALER_NAME"], [30, 1, 1, "", "SCHEDULER_NAME"], [30, 1, 1, "", "TRAINER_STATE_NAME"], [30, 1, 1, "", "TRAINING_ARGS_NAME"], [30, 1, 1, "", "_is_native_cpu_amp_available"], [30, 1, 1, "", "logger"], [30, 1, 1, "", "skip_first_batches"]], "lmflow.pipeline.utils.raft_trainer.RaftTrainer": [[30, 3, 1, "", "_add_sm_patterns_to_gitignore"], [30, 3, 1, "", "_gather_and_numpify"], [30, 3, 1, "", "_get_collator_with_removed_columns"], [30, 3, 1, "", "_get_eval_sampler"], [30, 3, 1, "", "_get_output_dir"], [30, 3, 1, "", "_get_train_sampler"], [30, 3, 1, "", "_hp_search_setup"], [30, 3, 1, "", "_inner_training_loop"], [30, 3, 1, "", "_issue_warnings_after_load"], [30, 3, 1, "", "_load_best_model"], [30, 3, 1, "", "_load_from_checkpoint"], [30, 3, 1, "", "_load_optimizer_and_scheduler"], [30, 3, 1, "", "_load_rng_state"], [30, 3, 1, "", "_maybe_log_save_evaluate"], [30, 3, 1, "", "_move_model_to_device"], [30, 3, 1, "", "_nested_gather"], [30, 3, 1, "", "_one_train"], [30, 3, 1, "", "_pad_across_processes"], [30, 3, 1, "", "_prepare_input"], [30, 3, 1, "", "_prepare_inputs"], [30, 3, 1, "", "_push_from_checkpoint"], [30, 3, 1, "", "_remove_unused_columns"], [30, 3, 1, "", "_report_to_hp_search"], [30, 3, 1, "", "_rotate_checkpoints"], [30, 3, 1, "", "_save"], [30, 3, 1, "", "_save_checkpoint"], [30, 3, 1, "", "_save_tpu"], [30, 3, 1, "", "_set_signature_columns_if_needed"], [30, 3, 1, "", "_sorted_checkpoints"], [30, 3, 1, "", "_tune_save_checkpoint"], [30, 3, 1, "", "_wrap_model"], [30, 3, 1, "", "add_callback"], [30, 3, 1, "", "autocast_smart_context_manager"], [30, 3, 1, "", "call_model_init"], [30, 3, 1, "", "compute_loss"], [30, 3, 1, "", "compute_loss_context_manager"], [30, 3, 1, "", "create_model_card"], [30, 3, 1, "", "create_optimizer"], [30, 3, 1, "", "create_optimizer_and_scheduler"], [30, 3, 1, "", "create_scheduler"], [30, 3, 1, "", "evaluate"], [30, 3, 1, "", "evaluation_loop"], [30, 3, 1, "", "floating_point_ops"], [30, 3, 1, "", "get_eval_dataloader"], [30, 3, 1, "", "get_optimizer_cls_and_kwargs"], [30, 3, 1, "", "get_test_dataloader"], [30, 3, 1, "", "get_train_dataloader"], [30, 3, 1, "", "hyperparameter_search"], [30, 3, 1, "", "init_git_repo"], [30, 3, 1, "", "ipex_optimize_model"], [30, 3, 1, "", "is_local_process_zero"], [30, 3, 1, "", "is_world_process_zero"], [30, 3, 1, "", "log"], [30, 3, 1, "", "num_examples"], [30, 3, 1, "", "pop_callback"], [30, 3, 1, "", "predict"], [30, 3, 1, "", "prediction_loop"], [30, 3, 1, "", "prediction_step"], [30, 3, 1, "", "push_to_hub"], [30, 3, 1, "", "remove_callback"], [30, 3, 1, "", "save_model"], [30, 3, 1, "", "store_flos"], [30, 3, 1, "", "torch_jit_model_eval"], [30, 3, 1, "", "train"], [30, 3, 1, "", "training_step"]], "lmflow.utils": [[31, 0, 0, "-", "constants"], [32, 0, 0, "-", "data_utils"]], "lmflow.utils.constants": [[31, 1, 1, "", "DATASET_DESCRIPTION_MAP"], [31, 1, 1, "", "FLOAT_ONLY_DATASET_DESCRIPTION"], [31, 1, 1, "", "INSTANCE_FIELDS_MAP"], [31, 1, 1, "", "TEXT2TEXT_DATASET_DESCRIPTION"], [31, 1, 1, "", "TEXT2TEXT_DATASET_DETAILS"], [31, 1, 1, "", "TEXT2TEXT_DATASET_LONG_DESCRITION"], [31, 1, 1, "", "TEXT_ONLY_DATASET_DESCRIPTION"], [31, 1, 1, "", "TEXT_ONLY_DATASET_DETAILS"], [31, 1, 1, "", "TEXT_ONLY_DATASET_LONG_DESCRITION"]], "lmflow.utils.data_utils": [[32, 5, 1, "", "answer_extraction"], [32, 5, 1, "", "batchlize"], [32, 5, 1, "", "load_data"], [32, 5, 1, "", "set_random_seed"]], "lmflow.version": [[34, 1, 1, "", "__version__"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:method", "4": "py:attribute", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"]}, "titleterms": {"contributor": 0, "changelog": 1, "version": [1, 34], "0": 1, "1": [1, 45], "mar": 1, "28": 1, "2023": 1, "about": 2, "lmflow": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 46], "arg": [3, 5], "api": 4, "refer": 4, "modul": [5, 6, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34], "content": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 46], "class": [5, 6, 7, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30], "attribut": [5, 6, 13, 14, 20, 25, 28, 30], "dataset": [6, 7, 40], "submodul": [7, 8, 15, 16, 26, 29, 33], "packag": [7, 8], "subpackag": [8, 15, 26], "model": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 36, 38, 45], "auto_model": 9, "base_model": 10, "decoder_model": 11, "encoder_decoder_model": 12, "hf_decoder_model": 13, "hf_encoder_decoder_model": 14, "interfac": [16, 17], "tunabl": 17, "regression_model": 18, "text_regression_model": 19, "pipelin": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "auto_pipelin": 20, "base_align": 21, "base_pipelin": 22, "base_tun": 23, "evalu": 24, "finetun": [25, 42, 43, 44, 45], "inferenc": 27, "function": [27, 32], "raft_align": 28, "util": [29, 30, 31, 32, 33], "raft_train": 30, "constant": 31, "data_util": 32, "data": [35, 36, 42], "document": 36, "prepar": [36, 42], "tune": [36, 39, 46], "infer": [36, 37, 42], "fine": 39, "format": 40, "gener": 40, "support": [40, 46], "detail": 40, "textonli": 40, "text2text": 40, "checkpoint": [41, 46], "llama": 41, "exampl": [42, 45], "reward": [44, 45], "rank": 44, "raft": 44, "introduct": [44, 45, 46], "algorithm": 44, "demo": 44, "custom": 44, "align": 44, "step": 45, "supervis": 45, "sft": 45, "2": 45, "featur": 46, "task": 46, "instruct": 46, "instal": 46, "citat": 46, "disclaim": 46, "indic": 46, "tabl": 46}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Contributors": [[0, "contributors"]], "Changelog": [[1, "changelog"]], "Version 0.0.1 (Mar 28, 2023)": [[1, "version-0-0-1-mar-28-2023"]], "About": [[2, "about"]], "lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "API Reference": [[4, "api-reference"]], "Module Contents": [[5, "module-contents"], [6, "module-contents"], [9, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [27, "module-contents"], [28, "module-contents"], [30, "module-contents"], [31, "module-contents"], [32, "module-contents"], [34, "module-contents"]], "Classes": [[5, "classes"], [6, "classes"], [7, "classes"], [9, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [13, "classes"], [14, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [27, "classes"], [28, "classes"], [30, "classes"]], "Attributes": [[5, "attributes"], [6, "attributes"], [13, "attributes"], [14, "attributes"], [20, "attributes"], [25, "attributes"], [28, "attributes"], [30, "attributes"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "Submodules": [[7, "submodules"], [8, "submodules"], [15, "submodules"], [16, "submodules"], [26, "submodules"], [29, "submodules"], [33, "submodules"]], "Package Contents": [[7, "package-contents"], [8, "package-contents"]], "lmflow": [[8, "module-lmflow"]], "Subpackages": [[8, "subpackages"], [15, "subpackages"], [26, "subpackages"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "lmflow.models.encoder_decoder_model": [[12, "module-lmflow.models.encoder_decoder_model"]], "lmflow.models.hf_decoder_model": [[13, "module-lmflow.models.hf_decoder_model"]], "lmflow.models.hf_encoder_decoder_model": [[14, "module-lmflow.models.hf_encoder_decoder_model"]], "lmflow.models": [[15, "module-lmflow.models"]], "lmflow.models.interfaces": [[16, "module-lmflow.models.interfaces"]], "lmflow.models.interfaces.tunable": [[17, "module-lmflow.models.interfaces.tunable"]], "lmflow.models.regression_model": [[18, "module-lmflow.models.regression_model"]], "lmflow.models.text_regression_model": [[19, "module-lmflow.models.text_regression_model"]], "lmflow.pipeline.auto_pipeline": [[20, "module-lmflow.pipeline.auto_pipeline"]], "lmflow.pipeline.base_aligner": [[21, "module-lmflow.pipeline.base_aligner"]], "lmflow.pipeline.base_pipeline": [[22, "module-lmflow.pipeline.base_pipeline"]], "lmflow.pipeline.base_tuner": [[23, "module-lmflow.pipeline.base_tuner"]], "lmflow.pipeline.evaluator": [[24, "module-lmflow.pipeline.evaluator"]], "lmflow.pipeline.finetuner": [[25, "module-lmflow.pipeline.finetuner"]], "lmflow.pipeline": [[26, "module-lmflow.pipeline"]], "lmflow.pipeline.inferencer": [[27, "module-lmflow.pipeline.inferencer"]], "Functions": [[27, "functions"], [32, "functions"]], "lmflow.pipeline.raft_aligner": [[28, "module-lmflow.pipeline.raft_aligner"]], "lmflow.pipeline.utils": [[29, "module-lmflow.pipeline.utils"]], "lmflow.pipeline.utils.raft_trainer": [[30, "module-lmflow.pipeline.utils.raft_trainer"]], "lmflow.utils.constants": [[31, "module-lmflow.utils.constants"]], "lmflow.utils.data_utils": [[32, "module-lmflow.utils.data_utils"]], "lmflow.utils": [[33, "module-lmflow.utils"]], "lmflow.version": [[34, "module-lmflow.version"]], "Data": [[35, "data"]], "Documentation": [[36, "documentation"]], "Data and Model Preparation": [[36, "data-and-model-preparation"]], "Model Tuning": [[36, "model-tuning"]], "Model Inference": [[36, "model-inference"]], "Inference": [[37, "inference"], [42, "inference"]], "Model": [[38, "model"]], "Fine-tuning": [[39, "fine-tuning"]], "Dataset": [[40, "dataset"]], "Dataset Format in General": [[40, "dataset-format-in-general"]], "Supported Dataset and Detailed Formats": [[40, "supported-dataset-and-detailed-formats"]], "TextOnly": [[40, "textonly"]], "Text2Text": [[40, "text2text"]], "Checkpoints": [[41, "checkpoints"], [46, "checkpoints"]], "LLaMA Checkpoint": [[41, "llama-checkpoint"]], "Examples": [[42, "examples"], [45, "examples"]], "Data preparation": [[42, "data-preparation"]], "Finetuning": [[42, "finetuning"]], "Finetune": [[43, "finetune"]], "Reward rAnked FineTuning (RAFT)": [[44, "reward-ranked-finetuning-raft"]], "Introduction": [[44, "introduction"], [45, "introduction"], [46, "introduction"]], "Algorithm": [[44, "algorithm"]], "Demo": [[44, "demo"]], "Customized Alignments": [[44, "customized-alignments"]], "Reward Modeling": [[45, "reward-modeling"]], "Step 1 Supervised Finetuning (SFT)": [[45, "step-1-supervised-finetuning-sft"]], "Step 2 Reward Modeling": [[45, "step-2-reward-modeling"]], "LMFlow": [[46, "lmflow"]], "Features": [[46, "features"]], "Task Tuning": [[46, "task-tuning"]], "Instruction Tuning": [[46, "instruction-tuning"]], "Installation": [[46, "installation"]], "Content": [[46, "content"]], "Citation": [[46, "citation"]], "Disclaimer": [[46, "disclaimer"]], "Support": [[46, "support"]], "Indices and tables": [[46, "indices-and-tables"]]}, "indexentries": {"lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "module": [[3, "module-lmflow.args"], [5, "module-lmflow.args"], [6, "module-lmflow.datasets.dataset"], [7, "module-lmflow.datasets"], [8, "module-lmflow"], [9, "module-lmflow.models.auto_model"], [10, "module-lmflow.models.base_model"], [11, "module-lmflow.models.decoder_model"], [12, "module-lmflow.models.encoder_decoder_model"], [13, "module-lmflow.models.hf_decoder_model"], [14, "module-lmflow.models.hf_encoder_decoder_model"], [15, "module-lmflow.models"], [16, "module-lmflow.models.interfaces"], [17, "module-lmflow.models.interfaces.tunable"], [18, "module-lmflow.models.regression_model"], [19, "module-lmflow.models.text_regression_model"], [20, "module-lmflow.pipeline.auto_pipeline"], [21, "module-lmflow.pipeline.base_aligner"], [22, "module-lmflow.pipeline.base_pipeline"], [23, "module-lmflow.pipeline.base_tuner"], [24, "module-lmflow.pipeline.evaluator"], [25, "module-lmflow.pipeline.finetuner"], [26, "module-lmflow.pipeline"], [27, "module-lmflow.pipeline.inferencer"], [28, "module-lmflow.pipeline.raft_aligner"], [29, "module-lmflow.pipeline.utils"], [30, "module-lmflow.pipeline.utils.raft_trainer"], [31, "module-lmflow.utils.constants"], [32, "module-lmflow.utils.data_utils"], [33, "module-lmflow.utils"], [34, "module-lmflow.version"]], "autoarguments (class in lmflow.args)": [[5, "lmflow.args.AutoArguments"]], "benchmarkingarguments (class in lmflow.args)": [[5, "lmflow.args.BenchmarkingArguments"]], "datasetarguments (class in lmflow.args)": [[5, "lmflow.args.DatasetArguments"]], "evaluatorarguments (class in lmflow.args)": [[5, "lmflow.args.EvaluatorArguments"]], "finetunerarguments (class in lmflow.args)": [[5, "lmflow.args.FinetunerArguments"]], "inferencerarguments (class in lmflow.args)": [[5, "lmflow.args.InferencerArguments"]], "model_config_classes (in module lmflow.args)": [[5, "lmflow.args.MODEL_CONFIG_CLASSES"]], "model_types (in module lmflow.args)": [[5, "lmflow.args.MODEL_TYPES"]], "modelarguments (class in lmflow.args)": [[5, "lmflow.args.ModelArguments"]], "pipeline_argument_mapping (in module lmflow.args)": [[5, "lmflow.args.PIPELINE_ARGUMENT_MAPPING"]], "raftalignerarguments (class in lmflow.args)": [[5, "lmflow.args.RaftAlignerArguments"]], "__post_init__() (lmflow.args.datasetarguments method)": [[5, "lmflow.args.DatasetArguments.__post_init__"]], "__post_init__() (lmflow.args.modelarguments method)": [[5, "lmflow.args.ModelArguments.__post_init__"]], "answer_type (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.answer_type"]], "arch_type (lmflow.args.modelarguments attribute)": [[5, "id0"], [5, "lmflow.args.ModelArguments.arch_type"]], "block_size (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.block_size"]], "cache_dir (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.cache_dir"]], "config_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_name"]], "config_overrides (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_overrides"]], "customized_cache_dir (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.customized_cache_dir"]], "dataset_config_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_config_name"]], "dataset_name (lmflow.args.benchmarkingarguments attribute)": [[5, "lmflow.args.BenchmarkingArguments.dataset_name"]], "dataset_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_name"]], "dataset_path (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_path"]], "deepspeed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.deepspeed"]], "deepspeed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.deepspeed"]], "device (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.device"]], "disable_group_texts (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.disable_group_texts"]], "do_sample (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.do_sample"]], "eval_dataset_path (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.eval_dataset_path"]], "evaluate_block_size (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.evaluate_block_size"]], "get_pipeline_args_class() (lmflow.args.autoarguments method)": [[5, "lmflow.args.AutoArguments.get_pipeline_args_class"]], "group_texts_batch_size (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.group_texts_batch_size"]], "inference_batch_size_per_device (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.inference_batch_size_per_device"]], "inference_batch_size_per_device (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.inference_batch_size_per_device"]], "is_custom_dataset (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.is_custom_dataset"]], "keep_linebreaks (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.keep_linebreaks"]], "lm_evaluation_metric (lmflow.args.benchmarkingarguments attribute)": [[5, "lmflow.args.BenchmarkingArguments.lm_evaluation_metric"]], "local_rank (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.local_rank"]], "local_rank (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.local_rank"]], "lora_alpha (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_alpha"]], "lora_dropout (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_dropout"]], "lora_model_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_model_path"]], "lora_r (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_r"]], "lora_target_modules (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_target_modules"]], "max_eval_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_eval_samples"]], "max_train_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_train_samples"]], "metric (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.metric"]], "mixed_precision (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.mixed_precision"]], "mixed_precision (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.mixed_precision"]], "model_name_or_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_name_or_path"]], "model_revision (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_revision"]], "model_type (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_type"]], "num_raft_iteration (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.num_raft_iteration"]], "output_dir (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.output_dir"]], "output_max_length (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_max_length"]], "output_min_length (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_min_length"]], "output_reward_path (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_reward_path"]], "overwrite_cache (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.overwrite_cache"]], "preprocessing_num_workers (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.preprocessing_num_workers"]], "prompt_structure (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.prompt_structure"]], "raft_batch_size (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.raft_batch_size"]], "random_seed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_seed"]], "random_seed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.random_seed"]], "random_shuffle (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_shuffle"]], "save_aggregated_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.save_aggregated_lora"]], "streaming (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.streaming"]], "test_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.test_file"]], "tokenizer_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.tokenizer_name"]], "top_reward_percentage (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.top_reward_percentage"]], "torch_dtype (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.torch_dtype"]], "train_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.train_file"]], "use_accelerator_for_evaluator (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.use_accelerator_for_evaluator"]], "use_auth_token (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_auth_token"]], "use_fast_tokenizer (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_fast_tokenizer"]], "use_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_lora"]], "use_ram_optimized_load (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_ram_optimized_load"]], "use_wandb (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.use_wandb"]], "validation_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_file"]], "validation_split_percentage (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_split_percentage"]], "dataset_types (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.DATASET_TYPES"]], "dataset (class in lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.Dataset"]], "key_instances (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_INSTANCES"]], "key_type (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_TYPE"]], "_check_data_format() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset._check_data_format"]], "create_from_dict() (lmflow.datasets.dataset.dataset class method)": [[6, "lmflow.datasets.dataset.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_data_args"]], "get_type() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_type"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "map() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.map"]], "to_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.to_dict"]], "dataset (class in lmflow.datasets)": [[7, "lmflow.datasets.Dataset"]], "_check_data_format() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset._check_data_format"]], "create_from_dict() (lmflow.datasets.dataset class method)": [[7, "lmflow.datasets.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_data_args"]], "get_type() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_type"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "map() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.map"]], "to_dict() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.to_dict"]], "__version__ (in module lmflow)": [[8, "lmflow.__version__"]], "internal_version (in module lmflow)": [[8, "lmflow.internal_version"]], "lmflow": [[8, "module-lmflow"]], "automodel (class in lmflow.models.auto_model)": [[9, "lmflow.models.auto_model.AutoModel"]], "get_model() (lmflow.models.auto_model.automodel class method)": [[9, "lmflow.models.auto_model.AutoModel.get_model"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "basemodel (class in lmflow.models.base_model)": [[10, "lmflow.models.base_model.BaseModel"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "decodermodel (class in lmflow.models.decoder_model)": [[11, "lmflow.models.decoder_model.DecoderModel"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "encoderdecodermodel (class in lmflow.models.encoder_decoder_model)": [[12, "lmflow.models.encoder_decoder_model.EncoderDecoderModel"]], "lmflow.models.encoder_decoder_model": [[12, "module-lmflow.models.encoder_decoder_model"]], "hfdecodermodel (class in lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel"]], "decode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.decode"]], "encode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_max_length"]], "get_tokenizer() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.inference"]], "lmflow.models.hf_decoder_model": [[13, "module-lmflow.models.hf_decoder_model"]], "logger (in module lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.save"]], "tokenize() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.tokenize"]], "hfencoderdecodermodel (class in lmflow.models.hf_encoder_decoder_model)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel"]], "decode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.decode"]], "encode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_max_length"]], "get_tokenizer() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.inference"]], "lmflow.models.hf_encoder_decoder_model": [[14, "module-lmflow.models.hf_encoder_decoder_model"]], "logger (in module lmflow.models.hf_encoder_decoder_model)": [[14, "lmflow.models.hf_encoder_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.save"]], "tokenize() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.tokenize"]], "lmflow.models": [[15, "module-lmflow.models"]], "lmflow.models.interfaces": [[16, "module-lmflow.models.interfaces"]], "tunable (class in lmflow.models.interfaces.tunable)": [[17, "lmflow.models.interfaces.tunable.Tunable"]], "lmflow.models.interfaces.tunable": [[17, "module-lmflow.models.interfaces.tunable"]], "regressionmodel (class in lmflow.models.regression_model)": [[18, "lmflow.models.regression_model.RegressionModel"]], "lmflow.models.regression_model": [[18, "module-lmflow.models.regression_model"]], "textregressionmodel (class in lmflow.models.text_regression_model)": [[19, "lmflow.models.text_regression_model.TextRegressionModel"]], "inference() (lmflow.models.text_regression_model.textregressionmodel method)": [[19, "lmflow.models.text_regression_model.TextRegressionModel.inference"]], "lmflow.models.text_regression_model": [[19, "module-lmflow.models.text_regression_model"]], "register_inference_function() (lmflow.models.text_regression_model.textregressionmodel method)": [[19, "lmflow.models.text_regression_model.TextRegressionModel.register_inference_function"]], "autopipeline (class in lmflow.pipeline.auto_pipeline)": [[20, "lmflow.pipeline.auto_pipeline.AutoPipeline"]], "pipeline_mapping (in module lmflow.pipeline.auto_pipeline)": [[20, "lmflow.pipeline.auto_pipeline.PIPELINE_MAPPING"]], "get_pipeline() (lmflow.pipeline.auto_pipeline.autopipeline class method)": [[20, "lmflow.pipeline.auto_pipeline.AutoPipeline.get_pipeline"]], "lmflow.pipeline.auto_pipeline": [[20, "module-lmflow.pipeline.auto_pipeline"]], "basealigner (class in lmflow.pipeline.base_aligner)": [[21, "lmflow.pipeline.base_aligner.BaseAligner"]], "_check_if_alignable() (lmflow.pipeline.base_aligner.basealigner method)": [[21, "lmflow.pipeline.base_aligner.BaseAligner._check_if_alignable"]], "align() (lmflow.pipeline.base_aligner.basealigner method)": [[21, "lmflow.pipeline.base_aligner.BaseAligner.align"]], "lmflow.pipeline.base_aligner": [[21, "module-lmflow.pipeline.base_aligner"]], "basepipeline (class in lmflow.pipeline.base_pipeline)": [[22, "lmflow.pipeline.base_pipeline.BasePipeline"]], "lmflow.pipeline.base_pipeline": [[22, "module-lmflow.pipeline.base_pipeline"]], "basetuner (class in lmflow.pipeline.base_tuner)": [[23, "lmflow.pipeline.base_tuner.BaseTuner"]], "_check_if_tunable() (lmflow.pipeline.base_tuner.basetuner method)": [[23, "lmflow.pipeline.base_tuner.BaseTuner._check_if_tunable"]], "lmflow.pipeline.base_tuner": [[23, "module-lmflow.pipeline.base_tuner"]], "tune() (lmflow.pipeline.base_tuner.basetuner method)": [[23, "lmflow.pipeline.base_tuner.BaseTuner.tune"]], "evaluator (class in lmflow.pipeline.evaluator)": [[24, "lmflow.pipeline.evaluator.Evaluator"]], "_evaluate_acc() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc"]], "_evaluate_nll() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_nll"]], "_evaluate_ppl() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_ppl"]], "_match() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._match"]], "create_dataloader() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator.create_dataloader"]], "evaluate() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator.evaluate"]], "lmflow.pipeline.evaluator": [[24, "module-lmflow.pipeline.evaluator"]], "finetuner (class in lmflow.pipeline.finetuner)": [[25, "lmflow.pipeline.finetuner.Finetuner"]], "group_text() (lmflow.pipeline.finetuner.finetuner method)": [[25, "lmflow.pipeline.finetuner.Finetuner.group_text"]], "lmflow.pipeline.finetuner": [[25, "module-lmflow.pipeline.finetuner"]], "logger (in module lmflow.pipeline.finetuner)": [[25, "lmflow.pipeline.finetuner.logger"]], "tune() (lmflow.pipeline.finetuner.finetuner method)": [[25, "lmflow.pipeline.finetuner.Finetuner.tune"]], "lmflow.pipeline": [[26, "module-lmflow.pipeline"]], "inferencer (class in lmflow.pipeline.inferencer)": [[27, "lmflow.pipeline.inferencer.Inferencer"]], "create_dataloader() (lmflow.pipeline.inferencer.inferencer method)": [[27, "lmflow.pipeline.inferencer.Inferencer.create_dataloader"]], "inference() (lmflow.pipeline.inferencer.inferencer method)": [[27, "lmflow.pipeline.inferencer.Inferencer.inference"]], "lmflow.pipeline.inferencer": [[27, "module-lmflow.pipeline.inferencer"]], "rstrip_partial_utf8() (in module lmflow.pipeline.inferencer)": [[27, "lmflow.pipeline.inferencer.rstrip_partial_utf8"]], "stream_inference() (lmflow.pipeline.inferencer.inferencer method)": [[27, "lmflow.pipeline.inferencer.Inferencer.stream_inference"]], "raftaligner (class in lmflow.pipeline.raft_aligner)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner"]], "_get_batch_dataset_top() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._get_batch_dataset_top"]], "_initialize_trainer() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._initialize_trainer"]], "_load_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._load_dataset"]], "_load_input_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._load_input_dataset"]], "align() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner.align"]], "lmflow.pipeline.raft_aligner": [[28, "module-lmflow.pipeline.raft_aligner"]], "logger (in module lmflow.pipeline.raft_aligner)": [[28, "lmflow.pipeline.raft_aligner.logger"]], "lmflow.pipeline.utils": [[29, "module-lmflow.pipeline.utils"]], "default_callbacks (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.DEFAULT_CALLBACKS"]], "default_progress_callback (in module lmflow.pipeline.utils.raft_trainer)": [[30, "id0"], [30, "lmflow.pipeline.utils.raft_trainer.DEFAULT_PROGRESS_CALLBACK"]], "is_sagemaker_mp_post_1_10 (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.IS_SAGEMAKER_MP_POST_1_10"]], "optimizer_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.OPTIMIZER_NAME"]], "rafttrainer (class in lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer"]], "scaler_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.SCALER_NAME"]], "scheduler_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.SCHEDULER_NAME"]], "trainer_state_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.TRAINER_STATE_NAME"]], "training_args_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.TRAINING_ARGS_NAME"]], "_add_sm_patterns_to_gitignore() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._add_sm_patterns_to_gitignore"]], "_gather_and_numpify() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._gather_and_numpify"]], "_get_collator_with_removed_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_collator_with_removed_columns"]], "_get_eval_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_eval_sampler"]], "_get_output_dir() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_output_dir"]], "_get_train_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_train_sampler"]], "_hp_search_setup() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._hp_search_setup"]], "_inner_training_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._inner_training_loop"]], "_is_native_cpu_amp_available (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer._is_native_cpu_amp_available"]], "_issue_warnings_after_load() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._issue_warnings_after_load"]], "_load_best_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_best_model"]], "_load_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_from_checkpoint"]], "_load_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_optimizer_and_scheduler"]], "_load_rng_state() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_rng_state"]], "_maybe_log_save_evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._maybe_log_save_evaluate"]], "_move_model_to_device() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._move_model_to_device"]], "_nested_gather() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._nested_gather"]], "_one_train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._one_train"]], "_pad_across_processes() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._pad_across_processes"]], "_prepare_input() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_input"]], "_prepare_inputs() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_inputs"]], "_push_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._push_from_checkpoint"]], "_remove_unused_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._remove_unused_columns"]], "_report_to_hp_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._report_to_hp_search"]], "_rotate_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._rotate_checkpoints"]], "_save() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save"]], "_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_checkpoint"]], "_save_tpu() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_tpu"]], "_set_signature_columns_if_needed() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._set_signature_columns_if_needed"]], "_sorted_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._sorted_checkpoints"]], "_tune_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._tune_save_checkpoint"]], "_wrap_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._wrap_model"]], "add_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.add_callback"]], "autocast_smart_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.autocast_smart_context_manager"]], "call_model_init() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.call_model_init"]], "compute_loss() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss"]], "compute_loss_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss_context_manager"]], "create_model_card() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_model_card"]], "create_optimizer() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer"]], "create_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer_and_scheduler"]], "create_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_scheduler"]], "evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluate"]], "evaluation_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluation_loop"]], "floating_point_ops() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.floating_point_ops"]], "get_eval_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_eval_dataloader"]], "get_optimizer_cls_and_kwargs() (lmflow.pipeline.utils.raft_trainer.rafttrainer static method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_optimizer_cls_and_kwargs"]], "get_test_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_test_dataloader"]], "get_train_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_train_dataloader"]], "hyperparameter_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.hyperparameter_search"]], "init_git_repo() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.init_git_repo"]], "ipex_optimize_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.ipex_optimize_model"]], "is_local_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_local_process_zero"]], "is_world_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_world_process_zero"]], "lmflow.pipeline.utils.raft_trainer": [[30, "module-lmflow.pipeline.utils.raft_trainer"]], "log() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.log"]], "logger (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.logger"]], "num_examples() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.num_examples"]], "pop_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.pop_callback"]], "predict() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.predict"]], "prediction_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_loop"]], "prediction_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_step"]], "push_to_hub() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.push_to_hub"]], "remove_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.remove_callback"]], "save_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.save_model"]], "skip_first_batches (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.skip_first_batches"]], "store_flos() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.store_flos"]], "torch_jit_model_eval() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.torch_jit_model_eval"]], "train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.train"]], "training_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.training_step"]], "dataset_description_map (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.DATASET_DESCRIPTION_MAP"]], "float_only_dataset_description (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.FLOAT_ONLY_DATASET_DESCRIPTION"]], "instance_fields_map (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.INSTANCE_FIELDS_MAP"]], "text2text_dataset_description (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT2TEXT_DATASET_DESCRIPTION"]], "text2text_dataset_details (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT2TEXT_DATASET_DETAILS"]], "text2text_dataset_long_descrition (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT2TEXT_DATASET_LONG_DESCRITION"]], "text_only_dataset_description (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT_ONLY_DATASET_DESCRIPTION"]], "text_only_dataset_details (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT_ONLY_DATASET_DETAILS"]], "text_only_dataset_long_descrition (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT_ONLY_DATASET_LONG_DESCRITION"]], "lmflow.utils.constants": [[31, "module-lmflow.utils.constants"]], "answer_extraction() (in module lmflow.utils.data_utils)": [[32, "lmflow.utils.data_utils.answer_extraction"]], "batchlize() (in module lmflow.utils.data_utils)": [[32, "lmflow.utils.data_utils.batchlize"]], "lmflow.utils.data_utils": [[32, "module-lmflow.utils.data_utils"]], "load_data() (in module lmflow.utils.data_utils)": [[32, "lmflow.utils.data_utils.load_data"]], "set_random_seed() (in module lmflow.utils.data_utils)": [[32, "lmflow.utils.data_utils.set_random_seed"]], "lmflow.utils": [[33, "module-lmflow.utils"]], "__version__ (in module lmflow.version)": [[34, "lmflow.version.__version__"]], "lmflow.version": [[34, "module-lmflow.version"]]}})